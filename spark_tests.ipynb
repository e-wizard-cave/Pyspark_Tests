{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YbymvNNQao0u"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing Pyspark and imports"
      ],
      "metadata": {
        "id": "YbymvNNQao0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark #Actually works unlike using [!wget -q \"URL\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcB-UViUVJnB",
        "outputId": "809073d7-6131-470f-fbbb-a3de5720b627"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=52432f861c33a6fc046aef1473c14a07f8c914022e6e21e55366680100e94dbf\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fVJhlGOdSGfY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder\\\n",
        ".appName('test') \\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "7gfL80j3X5oM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***This code will look for any csv file within the main directory***"
      ],
      "metadata": {
        "id": "BIKr0AY7Zzt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in os.listdir():\n",
        "  if '.csv' in file:\n",
        "    print(f'The size of the {file} file is {os.stat(file).st_size/(1024*1024):,.2f} MB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XjjCMlCYGXU",
        "outputId": "9152528f-139b-4b96-b22b-f9219caf3311"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the global_temperatures.csv file is 0.19 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***This os.listdir directs to the path folder \"read_test\"***"
      ],
      "metadata": {
        "id": "p-Wi1XFFZgsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in os.listdir('read_test'):\n",
        "  if '.csv' in file:\n",
        "    print(f'The size of the {file} file is {os.stat(\"read_test/\"+file).st_size/(1024*1024):,.2f} MB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_whiDtGZYtLS",
        "outputId": "affb4d11-f2dc-4305-b9c1-34d847a23950"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the global_temperatures.csv file is 0.19 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading the CSV file"
      ],
      "metadata": {
        "id": "aT86ASlnafjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df = spark.read.csv('global_temperatures.csv', header=True, inferSchema=True)\n"
      ],
      "metadata": {
        "id": "PyRG0GDzanhr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XySDtHCzbBvM",
        "outputId": "5d8c58db-44bb-4110-d88d-720a9053ad94"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------------------+---------------------------------+------------------+-----------------------------+------------------+-----------------------------+------------------------------+-----------------------------------------+\n",
            "|        dt|LandAverageTemperature|LandAverageTemperatureUncertainty|LandMaxTemperature|LandMaxTemperatureUncertainty|LandMinTemperature|LandMinTemperatureUncertainty|LandAndOceanAverageTemperature|LandAndOceanAverageTemperatureUncertainty|\n",
            "+----------+----------------------+---------------------------------+------------------+-----------------------------+------------------+-----------------------------+------------------------------+-----------------------------------------+\n",
            "|1776-08-01|                14.837|                            3.437|              NULL|                         NULL|              NULL|                         NULL|                          NULL|                                     NULL|\n",
            "|1777-08-01|                12.815|                            1.269|              NULL|                         NULL|              NULL|                         NULL|                          NULL|                                     NULL|\n",
            "|1777-09-01|    11.379000000000001|                            2.692|              NULL|                         NULL|              NULL|                         NULL|                          NULL|                                     NULL|\n",
            "|1766-12-01|                 2.333|                            2.278|              NULL|                         NULL|              NULL|                         NULL|                          NULL|                                     NULL|\n",
            "|1800-06-01|                13.606|                            1.169|              NULL|                         NULL|              NULL|                         NULL|                          NULL|                                     NULL|\n",
            "|1776-03-01|                 4.652|                            2.388|              NULL|                         NULL|              NULL|                         NULL|                          NULL|                                     NULL|\n",
            "|1794-01-01|                  3.71|                            3.869|              NULL|                         NULL|              NULL|                         NULL|                          NULL|                                     NULL|\n",
            "|1767-03-01|                 7.022|                            4.418|              NULL|                         NULL|              NULL|                         NULL|                          NULL|                                     NULL|\n",
            "|1829-11-01|                 5.003|                            1.449|              NULL|                         NULL|              NULL|                         NULL|                          NULL|                                     NULL|\n",
            "|1815-09-01|                11.151|                            1.503|              NULL|                         NULL|              NULL|                         NULL|                          NULL|                                     NULL|\n",
            "+----------+----------------------+---------------------------------+------------------+-----------------------------+------------------+-----------------------------+------------------------------+-----------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'There are {len(spark_df.columns)} columns and {spark_df.count():,} rows in the Pyspark DataFrame')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvNagBjIca5X",
        "outputId": "3b3786b8-29e9-47e1-95be-e0bfcab38f24"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 9 columns and 3,192 rows in the Pyspark DataFrame\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2nA1ep2ctYm",
        "outputId": "0f4db69c-056c-4bb4-d98b-71768d4cdb54"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- dt: date (nullable = true)\n",
            " |-- LandAverageTemperature: double (nullable = true)\n",
            " |-- LandAverageTemperatureUncertainty: double (nullable = true)\n",
            " |-- LandMaxTemperature: double (nullable = true)\n",
            " |-- LandMaxTemperatureUncertainty: double (nullable = true)\n",
            " |-- LandMinTemperature: double (nullable = true)\n",
            " |-- LandMinTemperatureUncertainty: double (nullable = true)\n",
            " |-- LandAndOceanAverageTemperature: double (nullable = true)\n",
            " |-- LandAndOceanAverageTemperatureUncertainty: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Schema"
      ],
      "metadata": {
        "id": "sM8tYg7Ic88O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([\n",
        "    StructField('Date', StringType(), True),\n",
        "    StructField('Land Avg Temp', StringType(), True),\n",
        "    StructField('Land Avg Temp(Uncertainty)', StringType(), True),\n",
        "    StructField('Land Max Temp', StringType(), True),\n",
        "    StructField('Land Max Temp(Uncertainty) 5', StringType(), True),\n",
        "    StructField('Land Min Temp', StringType(), True),\n",
        "    StructField('Land Min Temp(Uncertainty)', StringType(), True),\n",
        "    StructField('Land and Ocean Avg Temp', StringType(), True),\n",
        "    StructField('Land and Ocean Avg Temp(Uncertainty)', StringType(), True)\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "9RYCoTjKdBOi"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df2 = spark.read.csv('read_test/global_temperatures.csv', schema=schema, header=True)"
      ],
      "metadata": {
        "id": "N0HzLoz2fJON"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df2.show(6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDOz_cXEfP1s",
        "outputId": "ce676db7-ee9c-4f72-f3f4-7b6302dde95f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+--------------------------+-------------+----------------------------+-------------+--------------------------+-----------------------+------------------------------------+\n",
            "|      Date|     Land Avg Temp|Land Avg Temp(Uncertainty)|Land Max Temp|Land Max Temp(Uncertainty) 5|Land Min Temp|Land Min Temp(Uncertainty)|Land and Ocean Avg Temp|Land and Ocean Avg Temp(Uncertainty)|\n",
            "+----------+------------------+--------------------------+-------------+----------------------------+-------------+--------------------------+-----------------------+------------------------------------+\n",
            "|1776-08-01|            14.837|                     3.437|         NULL|                        NULL|         NULL|                      NULL|                   NULL|                                NULL|\n",
            "|1777-08-01|            12.815|                     1.269|         NULL|                        NULL|         NULL|                      NULL|                   NULL|                                NULL|\n",
            "|1777-09-01|11.379000000000001|                     2.692|         NULL|                        NULL|         NULL|                      NULL|                   NULL|                                NULL|\n",
            "|1766-12-01|             2.333|                     2.278|         NULL|                        NULL|         NULL|                      NULL|                   NULL|                                NULL|\n",
            "|1800-06-01|            13.606|                     1.169|         NULL|                        NULL|         NULL|                      NULL|                   NULL|                                NULL|\n",
            "|1776-03-01|             4.652|                     2.388|         NULL|                        NULL|         NULL|                      NULL|                   NULL|                                NULL|\n",
            "+----------+------------------+--------------------------+-------------+----------------------------+-------------+--------------------------+-----------------------+------------------------------------+\n",
            "only showing top 6 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}